{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ApplicantDayExercise2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raegar/LearningTensorFlow/blob/master/ApplicantDayExercise2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "nc3YoSMobglh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Step 1**\n",
        "\n",
        "Welcome to part two of your introduction to Machine Learning. Previously we looked at how we can train an AI to solve the algorithm to convert from Celcius to Fahrenheit. Next we will take a look at how we can use Neural Networks to recognise images and catagorise them!\n",
        "\n",
        "First we need some images to work with. As we will need thousands of consistent examples to train our network effectively we will use a publically available set of data known as Fashion MNIST. \n",
        "\n",
        "Let's load a collection of datasets that includes MNIST:"
      ]
    },
    {
      "metadata": {
        "id": "1Sl1yehoWSyp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U tensorflow_datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6ZgiruFgdE0M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Step 2**\n",
        "\n",
        "Next we will import the libaries we will use, TensorFlow, Math, NumPy, PyPlot and TQDM"
      ]
    },
    {
      "metadata": {
        "id": "B5U1H-fQWZsA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#impoert better progress bar display\n",
        "import tqdm\n",
        "import tqdm.auto\n",
        "tqdm.tqdm = tqdm.auto.tqdm\n",
        "\n",
        "print(tf.__version__)\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZR62nvgMdXmi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Step 3**\n",
        "\n",
        "The Fashion MNIST dataset contains 70,000 images of clothing items with tags letting us know what type of item each one is. We will need to split this collection into 60,000 training images and 10,000 test images so that when we carry out a test we are not using the exact same images that we used to train the model.\n",
        "\n",
        "&nbsp;\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n",
        "         alt=\"Fashion MNIST sprite\"  width=\"600\">\n",
        "  </td></tr>\n",
        "  <tr><td align=\"center\">\n",
        "    <b>Figure 1.</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">Fashion-MNIST samples</a> (by Zalando, MIT License).<br/>&nbsp;\n",
        "  </td></tr>\n",
        "</table>"
      ]
    },
    {
      "metadata": {
        "id": "aVm4NEd0WaZg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset, metadata = tfds.load('fashion_mnist', as_supervised=True, with_info=True)\n",
        "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
        "\n",
        "num_train_examples = metadata.splits['train'].num_examples\n",
        "num_test_examples = metadata.splits['test'].num_examples\n",
        "print(\"Number of training examples: {}\".format(num_train_examples))\n",
        "print(\"Number of test examples: {}\".format(num_test_examples))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "73qMfCIYd2xi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Step 4**\n",
        "\n",
        "Next we will create an array of labels that represet the 10 types of clothing stored in the Fashion MNIST Dataset"
      ]
    },
    {
      "metadata": {
        "id": "TYhEmjBodzWK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8eaKjx3yeLvq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Step 5**\n",
        "\n",
        "Image data is usually stored in bytes with 8 bits per colour channel. As the MNIST dataset is greyscale it only has 1 channel to represent each pixel. Therefore each pixel is represented by a value from 0 to 255. In order to work with the data it would be a good idea to 'normalize' the values so that we are working with values from 0.0 to 1.0 instead."
      ]
    },
    {
      "metadata": {
        "id": "JnjwPOMVWmLB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def normalize(images, labels): \n",
        "  images = tf.cast(images, tf.float32)\n",
        "  images /= 255\n",
        "  return images, labels\n",
        "\n",
        "train_dataset = train_dataset.map(normalize)\n",
        "test_dataset = test_dataset.map(normalize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UPh6re4We0Na",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Step 6**\n",
        "\n",
        "Now that we have the data normalised we can plot it to a grid where each value is a greyscale pixel. Let's take a single image from the dataset, format it as a 28x28 array and then plot it."
      ]
    },
    {
      "metadata": {
        "id": "uqKrTIp-WnxS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for image, label in test_dataset.take(1):\n",
        "  break\n",
        "image = image.numpy().reshape((28,28))\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(image, cmap=plt.cm.binary)\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v62iFqBdfoFK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Step 7**\n",
        "\n",
        "That works, so let's look at the first 30 images in the set along with their labels."
      ]
    },
    {
      "metadata": {
        "id": "Pgi64YeJWp7Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "i=0\n",
        "for(image, label) in test_dataset.take(30):\n",
        "  image = image.numpy().reshape((28,28))\n",
        "  plt.subplot(6,5,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(image, cmap=plt.cm.binary)\n",
        "  plt.xlabel(class_names[label])\n",
        "  i += 1\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pHjxt5Clf0n6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Step 8**\n",
        "\n",
        "In order to build our Neural Network model for training we will first have to flatten each image from a 28x28 single channel matrix into a flat vector (single dimension array). \n",
        "\n",
        "Then we will pass this data through a series of Dense layers, each with 128 Neurons.\n",
        "\n",
        "The Relu function will ensure that any value below 0 will be set to 0 so we don't get negative numbers.\n",
        "\n",
        "Finally the Softmax function will help to categorise each of the results into 1 of 10 possible categories (which is why there are 10 neurons on the final output layer)"
      ]
    },
    {
      "metadata": {
        "id": "T0IqL3y4Ws4Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=[28,28,1]),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nlNo1fDQg2WK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Step 9**\n",
        "\n",
        "We will compile the model that we just defined"
      ]
    },
    {
      "metadata": {
        "id": "sF4NlbY8Wuhp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VZE0zHFKg6ki",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Step 10**\n",
        "\n",
        "Now we can train the model using the training dataset and test it with the test dataset. We will split the images up into batches of 32 in order to make the process more discreet (in steps rather than trying to do all 60,000 at once!)"
      ]
    },
    {
      "metadata": {
        "id": "UcBU1yasWwgA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "train_dataset = train_dataset.repeat().shuffle(num_train_examples).batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "model.fit(train_dataset, epochs=7, steps_per_epoch=math.ceil(num_test_examples/32))\n",
        "test_loss, test_accuracy = model.evaluate(test_dataset, steps=math.ceil(num_test_examples/32))\n",
        "print(\"Accuracy on test dataset: {}\", test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XMzxeOvIhV77",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Step 11**\n",
        "\n",
        "We can use the shape property to check that the model actually does take 32 examples and outputs to 10 different catagories:"
      ]
    },
    {
      "metadata": {
        "id": "K_DqCLypWyUQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for test_images, test_labels in test_dataset.take(1):\n",
        "  test_images = test_images.numpy()\n",
        "  test_labels = test_labels.numpy()\n",
        "  predictions = model.predict(test_images)\n",
        "  \n",
        "predictions.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YqcB8DNIiDSD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now let's see how confident the model is at prediction if the first image in the set (image 0) is one of our 10 clothing types"
      ]
    },
    {
      "metadata": {
        "id": "w4o8c7aNW0gI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qM93OLlliUfT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can use the argmax function of NumPy to return the idex of the highest (most confident) category"
      ]
    },
    {
      "metadata": {
        "id": "xr1AZan1W2BQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.argmax(predictions[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zsBm0nJIivwj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And we can manually compare this value to the actual category of the first item of the set"
      ]
    },
    {
      "metadata": {
        "id": "WcczGx6cW3Np",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_labels[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yvN5lFuvi2sT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Hopefully they are the same number!"
      ]
    },
    {
      "metadata": {
        "id": "mBnweKxPi5Vz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Step 12**\n",
        "\n",
        "We can now plot the first image and a graph of the confidence to see these results"
      ]
    },
    {
      "metadata": {
        "id": "7SGxJbgOW6sR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_image(i, predictions_array, true_labels, images):\n",
        "  predictions_array, true_label, img = predictions_array[i], true_labels[i], images[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  \n",
        "  plt.imshow(img[...,0], cmap=plt.cm.binary)\n",
        "\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "  \n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                class_names[true_label]),\n",
        "                                color=color)\n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "  predictions_array, true_label = predictions_array[i], true_label[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
        "  plt.ylim([0, 1]) \n",
        "  predicted_label = np.argmax(predictions_array)\n",
        " \n",
        "  thisplot[predicted_label].set_color('red')\n",
        "  thisplot[true_label].set_color('blue')\n",
        "  \n",
        "\n",
        "i = 0\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions, test_labels, test_images)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions,  test_labels)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MphdDrTSjTFt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Step 13**\n",
        "\n",
        "Fianlly let's plot the first 25 images and their confidence values for each and see if the algorithm has accurately predicted what they are!"
      ]
    },
    {
      "metadata": {
        "id": "sWCpzMl3W9rI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_rows = 5\n",
        "num_cols = 5\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_image(i, predictions, test_labels, test_images)\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "  plot_value_array(i, predictions, test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rb9UUdIYa-W5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Exercises**\n",
        "\n",
        "Try to improve the fit of the model by changing \n",
        "* the number of layers in the model\n",
        "* the number of neurons in each layer\n",
        "* the number of epochs that the model trains for\n",
        "\n",
        "\n",
        "How does this change the accuracy of the results?"
      ]
    },
    {
      "metadata": {
        "id": "-SvSXh2wbie8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Where to next? To improve the accuarcy of the model further we will need to learn all about [Convolutional Neural Networks or CNNs!](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)"
      ]
    }
  ]
}